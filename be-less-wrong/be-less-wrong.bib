@InCollection{Martin-Baro1994B,
  author = {Ignacio Martín-Baró},
  city = {Cambridge, MA},
  editor = {Adrianne Aron and Shawn Corne},
  booktitle = {Writings for a liberation psychology},
  publisher = {Harvard University Press},
  title = {Toward A Liberation Psychology},
  year = {1994},
}

@InCollection{Silverman1998,
  author = {William A. Silverman},
  city = {New York, NY},
  booktitle = {Where's the Evidence? Debates in Modern Medicine},
  publisher = {Oxford University Press},
  title = {Non-replication of the replicable (1996)},
  year = {1998},
}

@InCollection{Box1979,
  title = {Robustness in the strategy of scientific
model building},
  booktitle = {Robustness in Statistics},
  editor = {Robert L. Launer and Graham N. Wilkinson},
  author = {George Box},
  publisher = {Academic Press, Inc. [Harcourt Brace Jovanovich, Publishers], New York-London},
  year = {1979},
  isbn = {0-12-438150-2},
}

@InCollection{MR0554183,
  title = {Robustness in statistics},
  booktitle = {Proceedings of a {W}orkshop held at the {A}rmy {R}esearch {O}ffice, {R}esearch {T}riangle {P}ark, {N}.{C}., {A}pril 11--12, 1978},
  editor = {Robert L. Launer and Graham N. Wilkinson},
  author = {Robert L. Launer and Graham N. Wilkinson},
  publisher = {Academic Press, Inc. [Harcourt Brace Jovanovich, Publishers], New York-London},
  year = {1979},
  pages = {xvi+296},
  isbn = {0-12-438150-2},
  mrclass = {62F35},
  mrnumber = {554183},
  mrreviewer = {Colin\ L.\ Mallows},
}

@Article{Hand2014,
  author = {David J. Hand},
  title = {{Wonderful Examples, but Let’s not Close Our Eyes}},
  volume = {29},
  journal = {Statistical Science},
  number = {1},
  publisher = {Institute of Mathematical Statistics},
  pages = {98 -- 100},
  abstract = {The papers in this collection are superb illustrations of the power of modern Bayesian methods. They give examples of problems which are well suited to being tackled using such methods, but one must not lose sight of the merits of having multiple different strategies and tools in one’s inferential armoury.},
  keywords = {frequentist, likelihood inference, Neyman–Pearson hypothesis testing, schools of inference},
  year = {2014},
  doi = {10.1214/13-STS446},
  url = {https://doi.org/10.1214/13-STS446},
}

@Article{Gelman2007,
  abstract = {For decades, the Democrats have been viewed as the party of the poor, with the Republicans representing the rich. Recent presidential elections, however, have shown a reverse pattern, with Democrats performing well in the richer blue states in the northeast and coasts, and Republicans dominating in the red states in the middle of the country and the south. Through multilevel modeling of individual-level survey data and county-and state-level demographic and electoral data, we reconcile these patterns. Furthermore, we find that income matters more in red America than in blue America. In poor states, rich people are much more likely than poor people to vote for the Republican presidential candidate, but in rich states (such as Connecticut), income has a very low correlation with vote preference.},
  author = {Andrew Gelman and Boris Shor and Joseph Bafumi and David Park},
  doi = {10.2139/ssrn.1010426},
  journal = {Quarterly Journal of Political Science},
  month = {11},
  pages = {345-367},
  title = {Rich State, Poor State, Red State, Blue State: What's the Matter with {C}onnecticut?},
  volume = {2},
  year = {2007},
}

@InCollection{DiezRoux2003,
  author = {Ana {Diez Roux}},
  city = {Dordrecht / Boston / London},
  editor = {Daniel Courgeau},
  booktitle = {Methodology and Epistemology of Multilevel Analysis:  Approaches from Different Social Sciences},
  pages = {93-119},
  publisher = {Kluwer Academic Publishers},
  title = {Potentialities and Limitations of Multilevel Analysis in Public Health and Epidemiology},
  year = {2003},
}

@Article{Simpson1951,
  abstract = {[The definition of second order interaction in a (2 × 2 × 2) table given by Bartlett is accepted, but it is shown by an example that the vanishing of this second order interaction does not necessarily justify the mechanical procedure of forming the three component 2 × 2 tables and testing each of these for significance by standard methods.]},
  author = {E H Simpson},
  issn = {00359246},
  issue = {2},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  pages = {238-241},
  publisher = {[Royal Statistical Society, Wiley]},
  title = {The Interpretation of Interaction in Contingency Tables},
  volume = {13},
  url = {http://www.jstor.org/stable/2984065},
  year = {1951},
}

@Article{Nieuwenhuis2015,
  author = {Rense Nieuwenhuis},
  journal = {Demographic Research},
  month = {3},
  title = {Association, Aggregation, and Paradoxes: On the Positive Correlation Between Fertility and Women’s Employment},
  volume = {32},
  url = {https://www.demographic-research.org/volumes/vol32/23/},
  year = {2015},
}

@article{Elwert2014,
   abstract = {Endogenous selection bias is a central problem for causal inference. Recognizing the problem, however, can be difficult in practice. This article introduces a purely graphical way of characterizing endogenous selection bias and of understanding its consequences (Hernán et al. 2004). We use causal graphs (direct acyclic graphs, or DAGs) to highlight that endogenous selection bias stems from conditioning (e.g., controlling, stratifying, or selecting) on a so-called collider variable, i.e., a variable that is itself caused by two other variables, one that is (or is associated with) the treatment and another that is (or is associated with) the outcome. Endogenous selection bias can result from direct conditioning on the outcome variable, a post-outcome variable, a post-treatment variable, and even a pre-treatment variable. We highlight the difference between endogenous selection bias, common-cause confounding, and overcontrol bias and discuss numerous examples from social stratification, cultural sociology, social network analysis, political sociology, social demography, and the sociology of education.},
   author = {Felix Elwert and Christopher Winship},
   doi = {10.1146/annurev-soc-071913-043455},
   issn = {0360-0572},
   issue = {1},
   journal = {Annual Review of Sociology},
   month = {7},
   note = {doi: 10.1146/annurev-soc-071913-043455},
   pages = {31-53},
   publisher = {Annual Reviews},
   title = {Endogenous Selection Bias: The Problem of Conditioning on a Collider Variable},
   volume = {40},
   url = {https://doi.org/10.1146/annurev-soc-071913-043455},
   year = {2014}
}

@article{Westreich2013,
   abstract = {It is common to present multiple adjusted effect estimates from a single model in a single table. For example, a table might show odds ratios for one or more exposures and also for several confounders from a single logistic regression. This can lead to mistaken interpretations of these estimates. We use causal diagrams to display the sources of the problems. Presentation of exposure and confounder effect estimates from a single model may lead to several interpretative difficulties, inviting confusion of direct-effect estimates with total-effect estimates for covariates in the model. These effect estimates may also be confounded even though the effect estimate for the main exposure is not confounded. Interpretation of these effect estimates is further complicated by heterogeneity (variation, modification) of the exposure effect measure across covariate levels. We offer suggestions to limit potential misunderstandings when multiple effect estimates are presented, including precise distinction between total and direct effect measures from a single model, and use of multiple models tailored to yield total-effect estimates for covariates.},
   author = {Daniel Westreich and Sander Greenland},
   doi = {10.1093/aje/kws412},
   issn = {0002-9262},
   issue = {4},
   journal = {American Journal of Epidemiology},
   month = {2},
   pages = {292-298},
   title = {The Table 2 Fallacy: Presenting and Interpreting Confounder and Modifier Coefficients},
   volume = {177},
   url = {https://doi.org/10.1093/aje/kws412},
   year = {2013}
}

@InCollection{langbliese,
  author = {Jonas W.B. Lang and Paul D. Bliese},
  year = {in press},
  city = {Cheltenham, UK},
  editor = {N. Bowling and M.K. Shoss and Z. Zhou},
  booktitle = {How to get published in the best industrial-organizational psychology journals},
  publisher = {Edward Elgar Publishing},
  title = {Multilevel Research Designs},
}

@Article{Diener2022,
  abstract = {It is often claimed that only experiments can support strong causal inferences and therefore they should be privileged in the behavioral sciences. We disagree. Overvaluing experiments results in their overuse both by researchers and decision makers and in an underappreciation of their shortcomings. Neglect of other methods often follows. Experiments can suggest whether X causes Y in a specific experimental setting; however, they often fail to elucidate either the mechanisms responsible for an effect or the strength of an effect in everyday natural settings. In this article, we consider two overarching issues. First, experiments have important limitations. We highlight problems with external, construct, statistical-conclusion, and internal validity; replicability; and conceptual issues associated with simple X causes Y thinking. Second, quasi-experimental and nonexperimental methods are absolutely essential. As well as themselves estimating causal effects, these other methods can provide information and understanding that goes beyond that provided by experiments. A research program progresses best when experiments are not treated as privileged but instead are combined with these other methods.},
  author = {Ed Diener and Robert Northcott and Michael J Zyphur and Stephen G West},
  doi = {10.1177/17456916211037670},
  issn = {1745-6916},
  issue = {4},
  journal = {Perspectives on Psychological Science},
  month = {2},
  note = {doi: 10.1177/17456916211037670},
  pages = {1101-1119},
  publisher = {SAGE Publications Inc},
  title = {Beyond Experiments},
  volume = {17},
  url = {https://doi.org/10.1177/17456916211037670},
  year = {2022},
}

@Article{Button2013,
  abstract = {Low statistical power undermines the purpose of scientific research; it reduces the chance of detecting a true effect. Perhaps less intuitively, low power also reduces the likelihood that a statistically significant result reflects a true effect. Empirically, we estimate the median statistical power of studies in the neurosciences is between ∼8% and ∼31%. We discuss the consequences of such low statistical power, which include overestimates of effect size and low reproducibility of results. There are ethical dimensions to the problem of low power; unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established, but often ignored, methodological principles. We discuss how problems associated with low power can be addressed by adopting current best-practice and make clear recommendations for how to achieve this.},
  author = {Katherine S Button and John P A Ioannidis and Claire Mokrysz and Brian A Nosek and Jonathan Flint and Emma S J Robinson and Marcus R Munaf\`{o}},
  doi = {10.1038/nrn3475},
  issn = {1471-0048},
  issue = {5},
  journal = {Nature Reviews Neuroscience},
  pages = {365-376},
  title = {Power failure: why small sample size undermines the reliability of neuroscience},
  volume = {14},
  url = {https://doi.org/10.1038/nrn3475},
  year = {2013},
}

@Article{Henrich2010,
  abstract = {Behavioral scientists routinely publish broad claims about human psychology and behavior in the world's top journals based on samples drawn entirely from Western, Educated, Industrialized, Rich and Democratic (WEIRD) societies. Researchers - often implicitly - assume that either there is little variation across human populations, or that these “standard subjects” are as representative of the species as any other population. Are these assumptions justified? Here, our review of the comparative database from across the behavioral sciences suggests both that there is substantial variability in experimental results across populations and that WEIRD subjects are particularly unusual compared with the rest of the species - frequent outliers. The domains reviewed include visual perception, fairness, cooperation, spatial reasoning, categorization and inferential induction, moral reasoning, reasoning styles, self-concepts and related motivations, and the heritability of IQ. The findings suggest that members of WEIRD societies, including young children, are among the least representative populations one could find for generalizing about humans. Many of these findings involve domains that are associated with fundamental aspects of psychology, motivation, and behavior - hence, there are no obvious a priori grounds for claiming that a particular behavioral phenomenon is universal based on sampling from a single subpopulation. Overall, these empirical patterns suggests that we need to be less cavalier in addressing questions of human nature on the basis of data drawn from this particularly thin, and rather unusual, slice of humanity. We close by proposing ways to structurally re‐organize the behavioral sciences to best tackle these challenges.},
  archiveprefix = {arXiv},
  arxivid = {arXiv:1011.1669v3},
  author = {Joseph Henrich and Steven J. Heine and Ara Norenzayan},
  journal = {Behavioral and Brain Sciences},
  doi = {10.1017/S0140525X0999152X},
  eprint = {arXiv:1011.1669v3},
  isbn = {0140-525X},
  issn = {14691825},
  keywords = {behavioral economics,cross-cultural research,cultural psychology,culture,evolutionary psychology,experiments,external validity,generalizability,human universals,population variability},
  pmid = {20550733},
  title = {{The weirdest people in the world?}},
  year = {2010},
}

@Article{Draper2022,
  abstract = {Abstract It has become increasingly apparent that publishing research on child development from certain countries is especially challenging. These countries have been referred to collectively as the Majority World, the Global South, non-WEIRD (Western, Educated, Industrial, Rich, and Democratic), or low- and middle-income countries. The aim of this paper is to draw attention to these persistent challenges, and provide constructive recommendations to contribute to better representation of children from these countries in child development research. In this paper, we outline the history of publication bias in developmental science, and issues of generalization of research from these countries and hence where it ?fits? in terms of publishing. The importance of explaining context is highlighted, including for research on measurement child development outcomes, and attention is drawn to the vicious publication-funding cycle that further exacerbates the challenges of publishing this research. Specific recommendations are made to assist child development journals achieve their stated goals of creating a more inclusive, equitable, diverse, and global field of child development.},
  author = {Catherine E Draper and Lisa M Barnett and Caylee J Cook and Jorge A Cuartas and Steven J Howard and Dana C McCoy and Rebecca Merkley and Andres Molano and Carolina Maldonado-Carreño and Jelena Obradovic and Gaia Scerif and Nadia C Valentini and Fotini Venetsanou and Aisha K Yousafzai},
  doi = {10.1002/icd.2375},
  issn = {1522-7227},
  issue = {n/a},
  journal = {Infant and Child Development},
  keywords = {Global South,LMIC,Majority World,WEIRD,publication bias},
  month = {10},
  note = {https://doi.org/10.1002/icd.2375},
  pages = {e2375},
  publisher = {John Wiley & Sons, Ltd},
  title = {Publishing child development research from around the world: An unfair playing field resulting in most of the world's child population under-represented in research},
  volume = {n/a},
  url = {https://doi.org/10.1002/icd.2375},
  year = {2022},
}

@Book{Antweiler2016,
  abstract = {Since the politicization of anthropology in the 1970s, most anthropologists have been reluctant to approach the topic of universals - that is, phenomena that occur regularly in all known human societies. In this volume, Christoph Antweiler reasserts the importance of these cross-cultural commonalities for anthropological research and for life and co-existence beyond the academy. The question presented here is how anthropology can help us approach humanity in its entirety, understanding the world less as a globe, with an emphasis on difference, but as a planet, from a vantage point open to commonalities. -- from back cover.},
  author = {Christoph Antweiler},
  city = {New York, NY},
  isbn = {9781785330933},
  keywords = {Anthropology -- Philosophy.,Anthropology Philosophy.,Civilization -- History.,Civilization History.,Civilization.,History.,Humanities | Philosophy,Universals (Philosophy)},
  publisher = {Berghahn},
  title = {Our common denominator: human universals revisited},
  year = {2016},
}
